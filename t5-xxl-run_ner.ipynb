{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8b2851-b4bc-43e7-b720-155f9e5d4d18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from util.multigpu_fused_adam import FusedAdam\n",
    "\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import time\n",
    "from os.path import join\n",
    "from datetime import datetime\n",
    "\n",
    "import util\n",
    "from util.runner import Runner\n",
    "\n",
    "from metrics import EREEvaluator\n",
    "\n",
    "class NERRunner(Runner):\n",
    "\n",
    "    def evaluate(self, model, tensor_examples, stored_info, step, predict=False):\n",
    "        evaluator = EREEvaluator()\n",
    "\n",
    "        eval_batch_size = 32\n",
    "        if any(substr in self.config[\"plm_pretrained_name_or_path\"].lower()\\\n",
    "           for substr in [\"pp\", \"11b\", \"3b\", \"xl\", \"xxl\", \"large\"]):\n",
    "            eval_batch_size = 16\n",
    "\n",
    "        util.runner.logger.info('Step %d: evaluating on %d samples with batch_size %d' % (\n",
    "            step, len(tensor_examples), eval_batch_size))\n",
    "\n",
    "        evalloader = DataLoader(\n",
    "            tensor_examples, batch_size=eval_batch_size, shuffle=False, \n",
    "            num_workers=0,\n",
    "            collate_fn=self.collate_fn, \n",
    "            pin_memory=True\n",
    "        )\n",
    "        model.eval()\n",
    "        for i, (doc_keys, tensor_example) in enumerate(evalloader):\n",
    "            example_gpu = {}\n",
    "\n",
    "            for k, v in tensor_example.items():\n",
    "                if v is not None:\n",
    "                    example_gpu[k] = v.to(self.device)\n",
    "            example_gpu['is_training'][:] = 0\n",
    "\n",
    "            with torch.no_grad(), torch.cuda.amp.autocast(\n",
    "                enabled=self.use_amp, dtype=torch.bfloat16\n",
    "            ):\n",
    "                output = model(**example_gpu)\n",
    "\n",
    "            for batch_id, doc_key in enumerate(doc_keys):\n",
    "                gold_res = model.extract_gold_res_from_gold_annotation(\n",
    "                    {k:v[batch_id] for k, v in tensor_example.items()}, \n",
    "                    stored_info['example'][doc_key]\n",
    "                )\n",
    "                decoded_results = model.decoding(\n",
    "                    {k:v[batch_id] for k,v in output.items()}, \n",
    "                    stored_info['example'][doc_key]\n",
    "                )\n",
    "\n",
    "                decoded_results.update(\n",
    "                    gold_res\n",
    "                )\n",
    "                evaluator.update(\n",
    "                    **decoded_results\n",
    "                )\n",
    "                if predict:\n",
    "                    util.runner.logger.info(stored_info['example'][doc_key])\n",
    "                    util.runner.logger.info(decoded_results)\n",
    "\n",
    "        p,r,f = evaluator.get_prf()\n",
    "        metrics = {\n",
    "            'Eval_Ent_Precision': p[0] * 100,\n",
    "            'Eval_Ent_Recall': r[0] * 100,\n",
    "            'Eval_Ent_F1': f[0] * 100\n",
    "        }\n",
    "        for k,v in metrics.items():\n",
    "            util.runner.logger.info('%s: %.4f'%(k, v))\n",
    "\n",
    "        return f[0] * 100, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9931e5d0-d4b1-4a49-94ae-325bcdd3f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"configs/ner.conf\"\n",
    "config_name = \"flant5_xxl\"\n",
    "gpu_id = 0\n",
    "\n",
    "runner = NERRunner(\n",
    "    config_file=config_file,\n",
    "    config_name=config_name,\n",
    "    gpu_id=gpu_id\n",
    ")\n",
    "\n",
    "#if saved_suffix is not None:\n",
    "#    model, start_epoch = runner.initialize_model(saved_suffix, continue_training=True)\n",
    "#    runner.train(model, continued=True, start_epoch=start_epoch)\n",
    "#else:\n",
    "\n",
    "model, _ = runner.initialize_model()\n",
    "runner.train(model, continued=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
